name: Test TestFlight PM Action

# This workflow allows you to test the action in your repository
# You can trigger it manually or on schedule for testing

on:
  # Manual trigger for testing
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Run in dry-run mode (no real issues created)'
        required: false
        default: 'true'
        type: boolean
      debug:
        description: 'Enable debug logging'
        required: false
        default: 'true' 
        type: boolean
      platform:
        description: 'Platform to test (github, linear, or both)'
        required: false
        default: 'github'
        type: choice
        options:
          - github
          - linear
          - both

  # Optional: Schedule for regular testing (commented out by default)
  # schedule:
  #   - cron: '0 9 * * *'  # Daily at 9 AM UTC

jobs:
  test-action:
    runs-on: ubuntu-latest
    name: Test TestFlight PM Action
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Test TestFlight PM Action
        uses: ./  # Use the local action
        with:
          # Core TestFlight Configuration
          testflight_issuer_id: ${{ secrets.TESTFLIGHT_ISSUER_ID }}
          testflight_key_id: ${{ secrets.TESTFLIGHT_KEY_ID }}
          testflight_private_key: ${{ secrets.TESTFLIGHT_PRIVATE_KEY }}
          app_id: ${{ secrets.APP_ID }}
          
          # Platform Configuration
          platform: ${{ github.event.inputs.platform || 'github' }}
          
          # GitHub Configuration (only needed if platform includes 'github')
          gthb_token: ${{ secrets.GTHB_TOKEN }}
          github_owner: ${{ github.repository_owner }}
          github_repo: ${{ github.event.repository.name }}
          
          # Linear Configuration (only needed if platform includes 'linear')
          linear_api_token: ${{ secrets.LINEAR_API_TOKEN }}
          linear_team_id: ${{ secrets.LINEAR_TEAM_ID }}
          
          # Testing Configuration
          dry_run: ${{ github.event.inputs.dry_run || 'true' }}
          debug: ${{ github.event.inputs.debug || 'true' }}
          
          # Process only recent feedback for testing
          processing_window_hours: 2
          
          # Optional: LLM Enhancement (uncomment to test)
          # enable_llm_enhancement: false
          # openai_api_key: ${{ secrets.OPENAI_API_KEY }}
          
          # Optional: Advanced features
          enable_duplicate_detection: true
          enable_codebase_analysis: false

      - name: Output Test Results
        if: always()
        run: |
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Dry Run:** ${{ github.event.inputs.dry_run || 'true' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Platform:** ${{ github.event.inputs.platform || 'github' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Debug:** ${{ github.event.inputs.debug || 'true' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ **Test completed successfully!**" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Test failed.** Check the logs above for details." >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "- Review the action logs above for any issues" >> $GITHUB_STEP_SUMMARY
          echo "- If testing with dry_run=false, check for created issues" >> $GITHUB_STEP_SUMMARY
          echo "- Verify your secrets are properly configured" >> $GITHUB_STEP_SUMMARY
